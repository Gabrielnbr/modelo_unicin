{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import inflection\n",
    "\n",
    "# import numpy    as np\n",
    "import pandas   as pd\n",
    "# import seaborn  as sns\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# from IPython.display        import Image\n",
    "# from IPython.core.display   import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos Sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importar_arquivos()-> list:\n",
    "    \"\"\"\n",
    "    Método para importar os DataFrames salvos no formato pkl.\n",
    "    Por enquanto não vamos receber dados externos, mas no futuro isso será implementado.\n",
    "    \"\"\"\n",
    "    \n",
    "    arquivos = os.listdir(__CAMINHO_RAW)\n",
    "    lista_arquivos = [arquivo for arquivo in arquivos if arquivo.endswith('.csv')]\n",
    "    \n",
    "    return lista_arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mundaca_tipo_date(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    \n",
    "    df['date'] = pd.to_datetime( df['date'] )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novas_colunas_date(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    # year\n",
    "    df['year'] = df['date'].dt.year\n",
    "    # month\n",
    "    df['month'] = df['date'].dt.month\n",
    "    # day\n",
    "    df['day'] = df['date'].dt.day\n",
    "    # week of year\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    # year week\n",
    "    df['year_week'] = df['date'].dt.strftime('%Y-%W')\n",
    "    # year month\n",
    "    df['year_month'] = df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "    df['data_br'] = df['date'].dt.strftime('%d/%m/%Y')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_df(df: pd.DataFrame):\n",
    "    df.to_pickle('../data/external/db_ajustado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renomear_colunas(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    \n",
    "    columns_old = df.columns\n",
    "    snakecase = lambda x : inflection.underscore(x)\n",
    "    columns_new = list(map(snakecase,columns_old))\n",
    "    df.columns = columns_new\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesclar_arquivos(lista_arquivos: list,)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Método para meclar os DataFrames. Aporveito para acrescentar 1 coluna de identificação da tabela.\n",
    "    Preciso colocar essa identificação para não misturar os dados na hora da análise.\n",
    "    \"\"\"\n",
    "    dfs = pd.DataFrame()\n",
    "    for arquivo in lista_arquivos:\n",
    "    \n",
    "        df = pd.read_csv( os.path.join( __CAMINHO_RAW, arquivo ) )\n",
    "        maquina = arquivo.split('_')[1]\n",
    "        df['maquina'] = maquina\n",
    "    \n",
    "        df = renomear_colunas(df)\n",
    "        df = mundaca_tipo_date(df)\n",
    "\n",
    "        if dfs.empty:\n",
    "            dfs = df\n",
    "        else:\n",
    "            if maquina in dfs['maquina'].values:\n",
    "\n",
    "                date = dfs.loc[dfs['maquina'] == maquina, 'date']\n",
    "                filtro = date.max()\n",
    "                df = df.loc[df['date'] > filtro]\n",
    "                \n",
    "                dfs = pd.concat([dfs,df], ignore_index=True)\n",
    "            else:\n",
    "                dfs = pd.concat([dfs,df], ignore_index=True)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "__CAMINHO_RAW = '../data/raw/'\n",
    "#__CAMINHO_RAW = 'E:/4_arquivos/1_projeto/modelo_unicin/src/data/raw'\n",
    "\n",
    "__CAMINHO_INTERIM = '../data/processed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arquivos = importar_arquivos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mesclar_arquivos(lista_arquivos=lista_arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_name</th>\n",
       "      <th>subscription_guid</th>\n",
       "      <th>date</th>\n",
       "      <th>resource_guid</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_type</th>\n",
       "      <th>service_region</th>\n",
       "      <th>service_resource</th>\n",
       "      <th>quantity</th>\n",
       "      <th>cost</th>\n",
       "      <th>maquina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35380</th>\n",
       "      <td>Microsoft Azure Sponsorship</td>\n",
       "      <td>15dc64f3-696a-48fc-9169-8467e3f7bba0</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>ed8a651a-e0a3-4de6-a8ae-3b4ce8cb72cf</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Files</td>\n",
       "      <td>All</td>\n",
       "      <td>LRS Data Stored</td>\n",
       "      <td>0.16128</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>unicin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subscription_name                     subscription_guid  \\\n",
       "35380  Microsoft Azure Sponsorship  15dc64f3-696a-48fc-9169-8467e3f7bba0   \n",
       "\n",
       "            date                         resource_guid service_name  \\\n",
       "35380 2024-05-02  ed8a651a-e0a3-4de6-a8ae-3b4ce8cb72cf      Storage   \n",
       "\n",
       "      service_type service_region service_resource  quantity      cost maquina  \n",
       "35380        Files            All  LRS Data Stored   0.16128  0.009672  unicin  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56933 entries, 0 to 56932\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   subscription_name  56933 non-null  object        \n",
      " 1   subscription_guid  56933 non-null  object        \n",
      " 2   date               56933 non-null  datetime64[ns]\n",
      " 3   resource_guid      56933 non-null  object        \n",
      " 4   service_name       56933 non-null  object        \n",
      " 5   service_type       56933 non-null  object        \n",
      " 6   service_region     56933 non-null  object        \n",
      " 7   service_resource   56933 non-null  object        \n",
      " 8   quantity           56933 non-null  float64       \n",
      " 9   cost               56933 non-null  float64       \n",
      " 10  maquina            56933 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(8)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subscription_name    0\n",
       "subscription_guid    0\n",
       "date                 0\n",
       "resource_guid        0\n",
       "service_name         0\n",
       "service_type         0\n",
       "service_region       0\n",
       "service_resource     0\n",
       "quantity             0\n",
       "cost                 0\n",
       "maquina              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = novas_colunas_date(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56933 entries, 0 to 56932\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   subscription_name  56933 non-null  object        \n",
      " 1   subscription_guid  56933 non-null  object        \n",
      " 2   date               56933 non-null  datetime64[ns]\n",
      " 3   resource_guid      56933 non-null  object        \n",
      " 4   service_name       56933 non-null  object        \n",
      " 5   service_type       56933 non-null  object        \n",
      " 6   service_region     56933 non-null  object        \n",
      " 7   service_resource   56933 non-null  object        \n",
      " 8   quantity           56933 non-null  float64       \n",
      " 9   cost               56933 non-null  float64       \n",
      " 10  maquina            56933 non-null  object        \n",
      " 11  year               56933 non-null  int32         \n",
      " 12  month              56933 non-null  int32         \n",
      " 13  day                56933 non-null  int32         \n",
      " 14  week_of_year       56933 non-null  UInt32        \n",
      " 15  year_week          56933 non-null  object        \n",
      " 16  year_month         56933 non-null  object        \n",
      " 17  data_br            56933 non-null  object        \n",
      "dtypes: UInt32(1), datetime64[ns](1), float64(2), int32(3), object(11)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportar_df(df=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('v3119')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9fd945bec87ea1faae53cf0492201e0c2959d8565ad017415241cf5b171a17a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
